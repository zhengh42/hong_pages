---
title: "Principal Components Analysis"
date: '2017-12-11'
slug: pca
categories: ["data at fingertips"]
tags: ["statistics"]
---

Denote the data matrix as `$X$`. Use the three functions in R (after center and scale the data):

```{r}
X.princomp = princomp(X, cor = T, scores = T) 
X.prcomp = prcomp(X,scale. = T) 
X.svd = svd(scale(X,center=TRUE,scale=TRUE))
```

|                      | princomp()                   | prcomp()              |         svd()         |
|    ---------         | ---------                 |   ---------              |  ---------    |
| standard deviations of principal components | sdev   | sdev  | `$\sqrt{(D^2/(n-1))}$`        |
| matrix of variable loadings | loadings  | rotation | V       |
| principal components | scores                   | x                   | U%*%D  |

Note:

* In svd approach, 
  - if p>n, `$X_{n*p}=U_{n*n}D_{n*n}V_{p*n}'$`
  - if p<n, `$X_{n*p}=U_{n*p}D_{p*p}V_{p*p}'$`. 
*  `$U$` and `$V$` has the following properties: `$V'V=I$`,  `$U'U=I$`; column sum of squares are ones. 
*  `$U$` has equal column variances, which is equal to `$\frac {1}{n-1} $`
* Loadings in princomp output, rotation in prcomp output, and v in svd outout are the matrix of variable loadings (columns are eigenvectors). Their row and column sum of squares are ones.

### How to get new principle components?

* Using princomp
  - X.princomp$scores
  - X %*% X.princomp$loadings
* Using prcomp  
  - X.prcomp$x
  -  X %*% X.prcomp$rotation
* Using svd
  - X.svd$u %*% diag(X.svd$d) (`$UD$`)
  - X %*% X.sdv$v  (`$XV$`)
  
princomp and prcomp outout have different signs.
  
### How to get loadings?  

* Using princomp
  - X.princomp$loadings
* Using prcomp  
  - X.prcomp$rotation
* Using svd
  - X.sdv$v
  
### How to get variance explained by each PC?

* Using princomp
  - column variance of X.princomp$scores
  - X.princomp$sdev^2
* Using prcomp  
  - column variance X.prcomp$x
  -  X.prcomp$sdev^2
* Using svd
  - Column variance of X.svd$u %*% diag(X.svd$d)
  - X.svd$d^2 divided by `$n-1$`


### eigenvectors and eigenvalues
http://setosa.io/ev/eigenvectors-and-eigenvalues/

### Nice illustrations by ttnphns et.al.

* __Variable space and subject space__  
https://stats.stackexchange.com/a/192637
* __Visual explanation of Canonical correlation analysis, PCA and Linear regression__  
https://stats.stackexchange.com/a/65817
* __Association measure of a variable with a PCA component (on a biplot / loading plot)__  
https://stats.stackexchange.com/a/119758
* __Principal component analysis and Factor analysis__  
https://stats.stackexchange.com/a/95106
* __Regression__  
https://stats.stackexchange.com/a/124892
* __Theoretical and pratical explanations of biplot__  
https://stats.stackexchange.com/a/141755  
https://stats.stackexchange.com/a/276746 
* __Loadings and eigenvectors__  
https://stats.stackexchange.com/a/143949

### More vivid explanation

https://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues/  

### PCA pratical tutorials using R

http://www.statpower.net/Content/312/R%20Stuff/PCA.html   
http://www.sthda.com/english/articles/31-principal-component-methods-in-r-practical-guide/112-pca-principal-component-analysis-essentials/  
https://rpubs.com/crazyhottommy/PCA_MDS  

 


