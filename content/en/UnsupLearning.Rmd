---
title: "Unsupervised learning"
output: html_document
---

```{r, dataset1, echo=TRUE, eval=TRUE,message=FALSE,warning=FALSE,fig.width=8,fig.height=8}
library(factoextra)

#####################
# read in data
#####################
library(ISLR)
data(College)
cdat = College[,2:18]
dim(cdat)
names(cdat)

#####################
# PCA
#####################

# princomp
cdat.princomp.scaled = princomp(cdat, cor = T, scores = T) 
cdat.princomp.unscaled = princomp(cdat, cor = F, scores = T) 

# prcomp
cdat.prcomp.scaled   = prcomp(cdat,scale. = T) 
cdat.prcomp.unscaled   = prcomp(cdat,scale. = F) 

# svd
cdat.sv = svd(scale(cdat,center=TRUE,scale=T))
cdat.sv.U = cdat.sv$u # 
cdat.sv.V = cdat.sv$v # PC Loadings, the same as cdat.prcomp.scaled$rotation
cdat.sv.D = cdat.sv$d # (cdat.sv.D^2)/(nrow(cdat)-1) is equal to cdat.prcomp.scaled$sdev^2
# The diagonal elements of D from the SVD are proportional to the standard deviations returned by PCA. The difference is that the standard deviations from prcomp are sample standard deviations (prcomp returns unbiased estimates of sample variance, so with the n-1 correction). The elements of D are formed by taking the sum of the squares of the principal components but not dividing by the sample size.
 # also equals to apply(cdat.sv.Z,2,function(x){sd(x)})/apply(cdat.sv.U,2,function(x){sd(x)})

cdat.sv.Z = scale(cdat,center=TRUE,scale=TRUE) %*% cdat.sv.V # PCs, the same as cdat.prcomp.scaled$x
all.equal(as.numeric(cdat.sv.Z), as.numeric(cdat.sv.U %*% diag(cdat.sv.D))) # PCs can also be obtained by UD

### explore

# scores in princomp output and x in prcomp output: The coordinates of the individuals (observations) on the principal components. 
# in princomp: data %*% loading == scores
# in prcomp: data %*% rotation == x
# prcomp output is more accurate?
all.equal(as.numeric(scale(cdat) %*% cdat.princomp.scaled$loadings[,1]) ,as.numeric(cdat.princomp.scaled$scores[,1]))
all.equal(as.numeric(scale(cdat) %*% cdat.princomp.scaled$loadings[,2]) ,as.numeric(cdat.princomp.scaled$scores[,2]))
all.equal(as.numeric(scale(cdat) %*% cdat.prcomp.scaled$rotation[,1]) ,as.numeric(cdat.prcomp.scaled$x[,1]))
all.equal(as.numeric(scale(cdat) %*% cdat.prcomp.scaled$rotation[,2]) ,as.numeric(cdat.prcomp.scaled$x[,2]))

# loadings in princomp output, rotation in prcomp output, and V in svd outout: the matrix of variable loadings (columns are eigenvectors).
# rotation in prcomp output and V in svd outout are the same
# loadings in princomp output and rotation in prcomp output: same absolute value, different sign
# column and row sum of squares of loadings/rotation is 1

all.equal(as.numeric(cdat.sv.V),as.numeric(cdat.prcomp.scaled$rotation))

apply(cdat.princomp.scaled$loadings,2,function(x){sum(x^2)})
apply(cdat.princomp.unscaled$loadings,2,function(x){sum(x^2)})
apply(cdat.prcomp.scaled$rotation,2,function(x){sum(x^2)})
apply(cdat.prcomp.unscaled$rotation,2,function(x){sum(x^2)})

apply(cdat.princomp.scaled$loadings,1,function(x){sum(x^2)})
apply(cdat.princomp.unscaled$loadings,1,function(x){sum(x^2)})
apply(cdat.prcomp.scaled$rotation,1,function(x){sum(x^2)})
apply(cdat.prcomp.unscaled$rotation,1,function(x){sum(x^2)})

# sdev is the column standard deviations of principal components. sdev^2 is the eigenvalue.
all.equal(apply(cdat.princomp.scaled$scores,2,function(x){sd(x)}),cdat.princomp.scaled$sdev)
all.equal(apply(cdat.princomp.unscaled$scores,2,function(x){sd(x)}),cdat.princomp.unscaled$sdev)
all.equal(as.numeric(apply(cdat.prcomp.scaled$x,2,function(x){sd(x)})),cdat.prcomp.scaled$sdev)
all.equal(as.numeric(apply(cdat.prcomp.unscaled$x,2,function(x){sd(x)})),cdat.prcomp.unscaled$sdev)

### biplot
par(mfrow=c(2,2))
biplot(cdat.princomp.scaled,cex=.7,sub="cdat.princomp.scaled")
biplot(cdat.princomp.unscaled,cex=.7,sub="cdat.princomp.unscaled")
biplot(cdat.prcomp.scaled,cex=.7,sub="cdat.prcomp.scaled")
biplot(cdat.prcomp.unscaled,cex=.7,sub="cdat.prcomp.unscaled")

### scatter plots 
par(mfrow=c(2,2))
i = 1; j = 2;
plot(cdat.princomp.scaled$scores[,i],cdat.princomp.scaled$scores[,j],pch=16,cex=.2,main="cdat.princomp.scaled")
text(cdat.princomp.scaled$scores[,i],cdat.princomp.scaled$scores[,j],rownames(cdat),cex=.6)
plot(cdat.princomp.unscaled$scores[,i],cdat.princomp.unscaled$scores[,j],pch=16,cex=.2,main="cdat.princomp.unscaled")
text(cdat.princomp.unscaled$scores[,i],cdat.princomp.unscaled$scores[,j],rownames(cdat),cex=.6)
plot(cdat.prcomp.scaled$x[,i],cdat.prcomp.scaled$x[,j],pch=16,cex=.2,main="cdat.prcomp.scaled")
text(cdat.prcomp.scaled$x[,i],cdat.prcomp.scaled$x[,j],rownames(cdat),cex=.6)
plot(cdat.prcomp.unscaled$x[,i],cdat.prcomp.unscaled$x[,j],pch=16,cex=.2,main="cdat.prcomp.unscaled")
text(cdat.prcomp.unscaled$x[,i],cdat.prcomp.unscaled$x[,j],rownames(cdat),cex=.6)

# look at a particular college
# ind = match("Harvard University",rownames(cdat))
# text(cdat.princomp.scaled$scores[ind,i],cdat.princomp.scaled$scores[ind,j],rownames(cdat)[ind],cex=.7,col=2)

###  how to look at variables that contribute to principal components?
par(mfrow=c(2,2))
barplot(cdat.princomp.scaled$loadings[,1],cex.names=.6,main="PC 1 Loadings of cdat.princomp.scaled")
barplot(cdat.princomp.unscaled$loadings[,1],cex.names=.6,main="PC 1 Loadings of cdat.princomp.unscaled")
barplot(cdat.prcomp.scaled$rotation[,1],cex.names=.6,main="PC 1 Loadings of cdat.prcomp.scaled")
barplot(cdat.prcomp.unscaled$rotation[,1],cex.names=.6,main="PC 1 Loadings of cdat.prcomp.unscaled")

### variance explained / eigenvalues
# functions from the factoextra package can also be used:
# fviz_eig(cdat.prcomp.scaled,addlabels = TRUE)
# fviz_screeplot()
# get_eigenvalue(cdat.prcomp.scaled)
# An eigenvalue > 1 indicates that PCs account for more variance than accounted by one of the original variables in standardized data. This is commonly used as a cutoff point for which PCs are retained. This holds true only when the data are standardized.
# You can also limit the number of component to that number that accounts for a certain fraction of the total variance. For example, if you are satisfied with 70% of the total variance explained then use the number of components to achieve that.

par(mfrow=c(2,2))
screeplot(cdat.princomp.scaled)
screeplot(cdat.princomp.unscaled)
screeplot(cdat.prcomp.scaled)
screeplot(cdat.prcomp.unscaled)

# cumulative variance explained

cdat.princomp.scaled.varex = 100*cdat.princomp.scaled$sdev^2/sum(cdat.princomp.scaled$sdev^2)
cdat.princomp.unscaled.varex = 100*cdat.princomp.unscaled$sdev^2/sum(cdat.princomp.unscaled$sdev^2)
cdat.prcomp.scaled.varex = 100*cdat.prcomp.scaled$sdev^2/sum(cdat.prcomp.scaled$sdev^2)
cdat.prcomp.unscaled.varex = 100*cdat.prcomp.unscaled$sdev^2/sum(cdat.prcomp.unscaled$sdev^2)

cdat.princomp.scaled.cvarex = NULL; for(i in 1:ncol(cdat)){cdat.princomp.scaled.cvarex[i] = sum(cdat.princomp.scaled.varex[1:i])}
cdat.princomp.unscaled.cvarex = NULL; for(i in 1:ncol(cdat)){cdat.princomp.unscaled.cvarex[i] = sum(cdat.princomp.unscaled.varex[1:i])}
cdat.prcomp.scaled.cvarex = NULL; for(i in 1:ncol(cdat)){cdat.prcomp.scaled.cvarex[i] = sum(cdat.prcomp.scaled.varex[1:i])}
cdat.prcomp.unscaled.cvarex = NULL; for(i in 1:ncol(cdat)){cdat.prcomp.unscaled.cvarex[i] = sum(cdat.prcomp.unscaled.varex[1:i])}

cdat.princomp.scaled.cvarex[1:3]/100
cdat.princomp.unscaled.cvarex[1:3]/100
cdat.prcomp.scaled.cvarex[1:3]/100
cdat.prcomp.unscaled.cvarex[1:3]/100

par(mfrow=c(2,2))
plot(cdat.princomp.scaled.cvarex,type="l",ylab="Cumulative Variance Explained",xlab="Component",main="cdat.princomp.scaled")
plot(cdat.princomp.unscaled.cvarex,type="l",ylab="Cumulative Variance Explained",xlab="Component",main="cdat.princomp.unscaled")
plot(cdat.prcomp.scaled.cvarex,type="l",ylab="Cumulative Variance Explained",xlab="Component",main="cdat.prcomp.scaled")
plot(cdat.prcomp.unscaled.cvarex,type="l",ylab="Cumulative Variance Explained",xlab="Component",main="cdat.prcomp.unscaled")

####### use factoextra
### Variables
cdat.prcomp.scaled.var <-get_pca_var(cdat.prcomp.scaled)
# cdat.prcomp.scaled.var$coord is coordinates of variables to create a scatter plot. It is equal to cdat.prcomp.scaled$rotation %*% diag(cdat.prcomp.scaled$sdev). The column sum of squares are the variances of PCs.
# cdat.prcomp.scaled.var$cos2: represents the quality of representation for variables on the factor map. Itâ€™s calculated as the squared coordinates: var.cos2 = var.coord * var.coord. The column sums are the variances of PCs.
# cdat.prcomp.scaled.var$contrib: contains the contributions (in percentage) of the variables to the principal components. The contribution of a variable (var) to a given principal component is (in percentage) : (var.cos2 * 100) / (total cos2 of the component).

# Correlation circle, which plots cdat.prcomp.scaled.var$coord (loadings, or covariances/correlations between the original variables and the unit-scaled components.)

fviz_pca_var(cdat.prcomp.scaled, col.var = "cos2",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), 
             repel = TRUE # Avoid text overlapping
             )

# cos2 values are used to estimate the quality of the representation of variables on PCs
library("corrplot")
corrplot(cdat.prcomp.scaled.var$cos2, is.corr=FALSE)
test<-fviz_cos2(cdat.prcomp.scaled, choice = "var", axes = 1:2)

# Contributions of variables to PCs
corrplot(cdat.prcomp.scaled.var$contrib, is.corr=FALSE)
fviz_contrib(cdat.prcomp.scaled, choice = "var", axes = 1:2,top=10) # Contributions of variables to PC1

### individuals
cdat.prcomp.scaled.ind <-get_pca_ind(cdat.prcomp.scaled)

fviz_pca_ind(cdat.prcomp.scaled, col.ind = "cos2", pointsize = "cos2",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = F # Avoid text overlapping (slow if many points)
             )

### biplot
# the coordinate of individuals and variables are not constructed on the same space. Therefore, in the biplot, you should mainly focus on the direction of variables but not on their absolute positions on the plot. An individual that is on the same side of a given variable has a high value for this variable; an individual that is on the opposite side of a given variable has a low value for this variable.
fviz_pca_biplot(cdat.prcomp.scaled, repel = F,
                col.var = "#2E9FDF", # Variables color
                col.ind = "#696969"  # Individuals color
                )

```


```{r}

#####################
# sparse PCA
#####################
library(PMA)

cdat.spc = SPC(scale(cdat),sumabsv=2,K=3)
cdat.spcL = cdat.spc$v
rownames(cdat.spcL) = names(cdat)

# scatterplots of Sparse PCs
par(mfrow=c(1,1))
i = 1; j = 2;
plot(cdat.spc$u[,i],cdat.spc$u[,j],pch=16,cex=.2)
text(cdat.spc$u[,i],cdat.spc$u[,j],rownames(cdat),cex=.6)

# loadings 
par(mfrow=c(2,1))
barplot(cdat.spc$v[,1],names=names(cdat),cex.names=.6,main="SPC 1 Loadings")
barplot(cdat.spc$v[,2],names=names(cdat),cex.names=.6,main="SPC 2 Loadings")

# variance explained
cdat.spc$prop.var.explained

```



```{r}
library(ISLR)
ncidat = NCI60$data
rownames(ncidat) = NCI60$labs
dim(ncidat) # 64 6830

X<-scale(scale(ncidat,center=TRUE,scale=FALSE))

ncidat.sv <- svd(X)
dim(ncidat.sv$u) # 64 64
dim(ncidat.sv$v) # 6830 64
plot(ncidat.sv$d)

```